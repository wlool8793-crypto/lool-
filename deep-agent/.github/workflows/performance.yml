name: Performance Testing

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    - cron: '0 1 * * 1'  # Weekly on Monday at 1 AM

jobs:
  load-testing:
    name: Load Testing
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up k6
        uses: grafana/k6-action@v0.3.0

      - name: Run API load test
        run: |
          k6 run tests/performance/api-load-test.js \
            --out json=api-load-results.json \
            --out cloud
        env:
          K6_CLOUD_TOKEN: ${{ secrets.K6_CLOUD_TOKEN }}
          TEST_URL: http://localhost:8000

      - name: Run WebSocket load test
        run: |
          k6 run tests/performance/websocket-load-test.js \
            --out json=websocket-load-results.json \
            --out cloud
        env:
          K6_CLOUD_TOKEN: ${{ secrets.K6_CLOUD_TOKEN }}
          TEST_URL: ws://localhost:8000

      - name: Run database load test
        run: |
          k6 run tests/performance/database-load-test.js \
            --out json=database-load-results.json \
            --out cloud
        env:
          K6_CLOUD_TOKEN: ${{ secrets.K6_CLOUD_TOKEN }}
          DATABASE_URL: postgresql://postgres:testpassword@localhost:5432/test_deep_agent

      - name: Upload load test results
        uses: actions/upload-artifact@v3
        with:
          name: load-test-results
          path: |
            api-load-results.json
            websocket-load-results.json
            database-load-results.json

  benchmarking:
    name: Performance Benchmarking
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install locust pytest-benchmark

      - name: Run API benchmarks
        run: |
          python -m pytest tests/benchmarks/api_benchmarks.py --benchmark-only --benchmark-json=api-benchmarks.json

      - name: Run database benchmarks
        run: |
          python -m pytest tests/benchmarks/database_benchmarks.py --benchmark-only --benchmark-json=database-benchmarks.json

      - name: Run LangGraph benchmarks
        run: |
          python -m pytest tests/benchmarks/langgraph_benchmarks.py --benchmark-only --benchmark-json=langgraph-benchmarks.json

      - name: Upload benchmark results
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-results
          path: |
            api-benchmarks.json
            database-benchmarks.json
            langgraph-benchmarks.json

      - name: Compare with previous benchmarks
        uses: benchmark-action/github-action-benchmark@v1
        if: github.event_name == 'pull_request'
        with:
          tool: 'pytest'
          output-file-path: api-benchmarks.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true

  memory-profiling:
    name: Memory Profiling
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install memory-profiler psutil

      - name: Run memory profiling
        run: |
          python tests/performance/memory_profile.py > memory-profile.txt

      - name: Generate memory heatmap
        run: |
          python tests/performance/generate_memory_heatmap.py

      - name: Upload memory profile results
        uses: actions/upload-artifact@v3
        with:
          name: memory-profile-results
          path: |
            memory-profile.txt
            memory-heatmap.png

  database-performance:
    name: Database Performance
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: testpassword
          POSTGRES_DB: test_deep_agent
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install psycopg2-binary

      - name: Run database performance tests
        run: |
          python tests/performance/database_performance.py
        env:
          DATABASE_URL: postgresql://postgres:testpassword@localhost:5432/test_deep_agent

      - name: Analyze query performance
        run: |
          python tests/performance/query_analysis.py > query-analysis.txt

      - name: Upload database performance results
        uses: actions/upload-artifact@v3
        with:
          name: database-performance-results
          path: |
            query-analysis.txt
            performance-metrics.json

  redis-performance:
    name: Redis Performance Testing
    runs-on: ubuntu-latest
    services:
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install redis

      - name: Run Redis performance tests
        run: |
          python tests/performance/redis_performance.py
        env:
          REDIS_URL: redis://localhost:6379

      - name: Upload Redis performance results
        uses: actions/upload-artifact@v3
        with:
          name: redis-performance-results
          path: redis-performance-metrics.json

  langgraph-performance:
    name: LangGraph Performance Testing
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run LangGraph performance tests
        run: |
          python tests/performance/langgraph_performance.py > langgraph-performance.txt

      - name: Measure agent execution time
        run: |
          python tests/performance/agent_execution_time.py > execution-time.txt

      - name: Upload LangGraph performance results
        uses: actions/upload-artifact@v3
        with:
          name: langgraph-performance-results
          path: |
            langgraph-performance.txt
            execution-time.txt

  performance-summary:
    name: Performance Summary
    runs-on: ubuntu-latest
    needs: [load-testing, benchmarking, memory-profiling, database-performance, redis-performance, langgraph-performance]
    if: always()

    steps:
      - name: Download all performance artifacts
        uses: actions/download-artifact@v3

      - name: Generate performance summary
        run: |
          echo "# Performance Test Summary" > performance-summary.md
          echo "Generated on: $(date)" >> performance-summary.md
          echo "" >> performance-summary.md

          echo "## Load Testing Results" >> performance-summary.md
          if [ -f "load-test-results/api-load-results.json" ]; then
            echo "### API Load Test" >> performance-summary.md
            head -20 load-test-results/api-load-results.json >> performance-summary.md
          fi

          echo "## Benchmark Results" >> performance-summary.md
          if [ -f "benchmark-results/api-benchmarks.json" ]; then
            echo "### API Benchmarks" >> performance-summary.md
            head -20 benchmark-results/api-benchmarks.json >> performance-summary.md
          fi

          echo "## Memory Usage" >> performance-summary.md
          if [ -f "memory-profile-results/memory-profile.txt" ]; then
            echo "\`\`\`" >> performance-summary.md
            head -30 memory-profile-results/memory-profile.txt >> performance-summary.md
            echo "\`\`\`" >> performance-summary.md
          fi

      - name: Upload performance summary
        uses: actions/upload-artifact@v3
        with:
          name: performance-summary
          path: performance-summary.md

      - name: Comment on performance degradation
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');

            // Check for performance degradation and comment if needed
            // This is a simplified example
            const comment = `Performance tests completed. Please review the performance artifacts for any regressions.`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });