"""
URL Classifier for Selenium Optimization (Phase 4 - Stage 1)

Classifies URLs to determine if they require JavaScript rendering (Selenium)
or can be downloaded directly with HTTP requests for better performance.

Performance Impact:
- Direct HTTP: 90% of URLs (PDFs, simple pages)
- Selenium: 10% of URLs (search pages, dynamic content)
- Speed improvement: 3-5X for direct downloads
"""

import re
from typing import Dict, Tuple
from urllib.parse import urlparse, parse_qs
import logging

logger = logging.getLogger(__name__)


class URLClassifier:
    """
    Classifies URLs to optimize download strategy.

    Strategy:
    - Direct PDF links ‚Üí Direct HTTP download (fast)
    - Static HTML pages ‚Üí Direct HTTP download (fast)
    - Search/browse pages ‚Üí Selenium (JavaScript required)
    - Dynamic content ‚Üí Selenium (JavaScript required)
    """

    def __init__(self):
        """Initialize URL classifier with pattern rules"""

        # Patterns for URLs that REQUIRE Selenium (JavaScript rendering)
        self.selenium_required_patterns = [
            r'/search/',            # Search pages
            r'/browse/',            # Browse pages
            r'/advanced_search/',   # Advanced search
            r'\?formInput=',        # Form-based searches
            r'\?q=',                # Query parameters
            r'/filter/',            # Filter pages
            r'/category/',          # Category browsing
        ]

        # Patterns for URLs that can use DIRECT HTTP
        self.direct_http_patterns = [
            r'\.pdf$',              # Direct PDF links
            r'/doc/\d+',            # Document pages (static HTML)
            r'/judgment/\d+',       # Judgment pages
            r'/case/\d+',           # Case pages
            r'/download/',          # Direct download links
            r'/pdf/',               # PDF directory
        ]

        # Compile regex patterns for performance
        self.selenium_regexes = [re.compile(p, re.IGNORECASE) for p in self.selenium_required_patterns]
        self.direct_regexes = [re.compile(p, re.IGNORECASE) for p in self.direct_http_patterns]

        # Statistics
        self.stats = {
            'direct_http': 0,
            'selenium': 0,
            'unknown': 0
        }

    def requires_javascript(self, url: str) -> bool:
        """
        Determine if URL requires JavaScript rendering (Selenium).

        Args:
            url: URL to classify

        Returns:
            True if Selenium required, False if direct HTTP can be used
        """
        classification, confidence, reason = self.classify_url(url)
        return classification == 'selenium'

    def classify_url(self, url: str) -> Tuple[str, float, str]:
        """
        Classify URL and provide detailed classification result.

        Args:
            url: URL to classify

        Returns:
            Tuple of (classification, confidence, reason)
            - classification: 'direct_http', 'selenium', or 'unknown'
            - confidence: 0.0-1.0 confidence in classification
            - reason: Human-readable reason for classification
        """
        # Parse URL
        parsed = urlparse(url)
        path = parsed.path.lower()
        query = parsed.query.lower()
        full_url = url.lower()

        # Priority 1: Check for direct PDF links (highest confidence)
        if path.endswith('.pdf'):
            self.stats['direct_http'] += 1
            return ('direct_http', 1.0, 'Direct PDF file link')

        # Priority 2: Check for download/PDF directories
        if '/download/' in path or '/pdf/' in path:
            self.stats['direct_http'] += 1
            return ('direct_http', 0.95, 'Download/PDF directory')

        # Priority 3: Check for document ID patterns (static pages)
        # Pattern: /doc/12345 or /judgment/67890
        doc_pattern = re.compile(r'/(?:doc|judgment|case)/\d+', re.IGNORECASE)
        if doc_pattern.search(path):
            self.stats['direct_http'] += 1
            return ('direct_http', 0.90, 'Document ID pattern (static HTML)')

        # Priority 4: Check for search/browse pages (require JavaScript)
        for pattern in self.selenium_regexes:
            if pattern.search(full_url):
                self.stats['selenium'] += 1
                return ('selenium', 0.95, f'Matches Selenium pattern: {pattern.pattern}')

        # Priority 5: Check query parameters
        if query:
            # Form-based queries usually need JavaScript
            if 'forminput=' in query or 'q=' in query:
                self.stats['selenium'] += 1
                return ('selenium', 0.85, 'Form/query parameters detected')

            # But direct PDF parameters are OK
            if 'pdf=1' in query or 'download=1' in query:
                self.stats['direct_http'] += 1
                return ('direct_http', 0.80, 'Direct download query parameter')

        # Priority 6: Check for specific IndianKanoon patterns
        if 'indiankanoon.org/doc/' in full_url:
            self.stats['direct_http'] += 1
            return ('direct_http', 0.85, 'IndianKanoon document URL pattern')

        # Default: If unsure, use Selenium (safer but slower)
        self.stats['unknown'] += 1
        logger.debug(f"Unknown URL classification: {url}")
        return ('selenium', 0.50, 'Unknown pattern - defaulting to Selenium for safety')

    def get_download_strategy(self, url: str) -> Dict[str, any]:
        """
        Get recommended download strategy for URL.

        Args:
            url: URL to analyze

        Returns:
            Dictionary with download strategy:
            {
                'method': 'direct_http' or 'selenium',
                'confidence': 0.0-1.0,
                'reason': str,
                'recommended_timeout': int (seconds),
                'max_retries': int
            }
        """
        classification, confidence, reason = self.classify_url(url)

        if classification == 'direct_http':
            return {
                'method': 'direct_http',
                'confidence': confidence,
                'reason': reason,
                'recommended_timeout': 30,  # Fast timeout for direct downloads
                'max_retries': 3,
                'use_selenium': False
            }
        else:  # selenium or unknown
            return {
                'method': 'selenium',
                'confidence': confidence,
                'reason': reason,
                'recommended_timeout': 60,  # Longer timeout for JavaScript
                'max_retries': 2,
                'use_selenium': True
            }

    def get_statistics(self) -> Dict[str, any]:
        """
        Get classification statistics.

        Returns:
            Dictionary with classification counts and percentages
        """
        total = sum(self.stats.values())
        if total == 0:
            return {
                'total': 0,
                'direct_http': {'count': 0, 'percentage': 0.0},
                'selenium': {'count': 0, 'percentage': 0.0},
                'unknown': {'count': 0, 'percentage': 0.0}
            }

        return {
            'total': total,
            'direct_http': {
                'count': self.stats['direct_http'],
                'percentage': round(self.stats['direct_http'] / total * 100, 2)
            },
            'selenium': {
                'count': self.stats['selenium'],
                'percentage': round(self.stats['selenium'] / total * 100, 2)
            },
            'unknown': {
                'count': self.stats['unknown'],
                'percentage': round(self.stats['unknown'] / total * 100, 2)
            }
        }

    def print_statistics(self):
        """Print classification statistics in human-readable format"""
        stats = self.get_statistics()

        print("\n" + "="*70)
        print("URL Classification Statistics")
        print("="*70)
        print(f"Total URLs classified: {stats['total']:,}")
        print(f"\nBreakdown:")
        print(f"  Direct HTTP:  {stats['direct_http']['count']:>8,} ({stats['direct_http']['percentage']:>5.1f}%) - Fast downloads")
        print(f"  Selenium:     {stats['selenium']['count']:>8,} ({stats['selenium']['percentage']:>5.1f}%) - JavaScript required")
        print(f"  Unknown:      {stats['unknown']['count']:>8,} ({stats['unknown']['percentage']:>5.1f}%) - Defaulted to Selenium")
        print("="*70)

        if stats['total'] > 0:
            efficiency_gain = stats['direct_http']['percentage'] * 3  # 3X faster for direct
            print(f"\nEstimated efficiency gain: ~{efficiency_gain:.0f}% faster overall")
            print(f"(Assuming direct HTTP is 3X faster than Selenium)")
            print("="*70)


# Global instance for easy import
url_classifier = URLClassifier()


def requires_selenium(url: str) -> bool:
    """
    Convenience function to check if URL requires Selenium.

    Args:
        url: URL to check

    Returns:
        True if Selenium required, False otherwise

    Example:
        >>> from src.url_classifier import requires_selenium
        >>> requires_selenium('https://indiankanoon.org/doc/12345.pdf')
        False
        >>> requires_selenium('https://indiankanoon.org/search/?q=murder')
        True
    """
    return url_classifier.requires_javascript(url)


# Example usage and testing
if __name__ == '__main__':
    print("URL Classifier Test Suite")
    print("="*70)

    test_urls = [
        # Direct HTTP (should be fast)
        'https://indiankanoon.org/doc/12345.pdf',
        'https://indiankanoon.org/doc/123456',
        'https://indiankanoon.org/judgment/98765',
        'https://indiankanoon.org/download/document.pdf',
        'https://indiankanoon.org/pdf/12345.pdf',

        # Selenium required (slower)
        'https://indiankanoon.org/search/?formInput=murder',
        'https://indiankanoon.org/search/?q=copyright',
        'https://indiankanoon.org/browse/category/family',
        'https://indiankanoon.org/advanced_search/?court=supreme',

        # Edge cases
        'https://indiankanoon.org/doc/123?pdf=1',
        'https://indiankanoon.org/unknown/path/here',
    ]

    classifier = URLClassifier()

    for url in test_urls:
        classification, confidence, reason = classifier.classify_url(url)
        method_icon = "üöÄ" if classification == 'direct_http' else "üêå"
        print(f"\n{method_icon} {url}")
        print(f"   ‚Üí {classification.upper()} (confidence: {confidence:.0%})")
        print(f"   ‚Üí Reason: {reason}")

    # Print statistics
    classifier.print_statistics()
